{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Lower Casing**\n",
        "\n"
      ],
      "metadata": {
        "id": "rXO2Be2VJV7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Hy my name is nikhil and it was a nice experience with NLP. Come on guys, Do play with NLP techniques.'\"\n",
        "text_lower = s.lower()\n",
        "print(text_lower)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WByfMLc_JNu6",
        "outputId": "e2d03075-824c-40aa-9c27-8799bf1efe87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hy my name is nikhil and it was a nice experience with nlp. come on guys, do play with nlp techniques.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**"
      ],
      "metadata": {
        "id": "gAdnXANIJBx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JxsCNx4vWPTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c38be2c-8872-4f0d-dc7b-aff9aa1b1597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hy\n",
            "my\n",
            "name\n",
            "is\n",
            "nikhil\n",
            "and\n",
            "it\n",
            "was\n",
            "a\n",
            "nice\n",
            "experience\n",
            "with\n",
            "NLP\n",
            ".\n",
            "Come\n",
            "on\n",
            "guys\n",
            ",\n",
            "Do\n",
            "play\n",
            "with\n",
            "NLP\n",
            "techniques\n",
            ".\n",
            "'\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "doc=nlp(s)\n",
        "for i in doc:\n",
        "  print(i.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Punctuations and Digits**"
      ],
      "metadata": {
        "id": "lQmxVHjQLh6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "punct_digit=[i.text for i in doc if not i.is_punct and not i.is_digit]\n",
        "print(punct_digit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpt2LLNgK4D6",
        "outputId": "3408f269-251d-4564-d460-78c98b3a139a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hy', 'my', 'name', 'is', 'nikhil', 'and', 'it', 'was', 'a', 'nice', 'experience', 'with', 'NLP', 'Come', 'on', 'guys', 'Do', 'play', 'with', 'NLP', 'techniques']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop Words**"
      ],
      "metadata": {
        "id": "p-zoBs2CMhvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = [token.text for token in doc if not token.is_stop]\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lceqKLTdL-I6",
        "outputId": "842744c9-4b09-41ed-b85e-38f98a13c75c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hy', 'nikhil', 'nice', 'experience', 'NLP', '.', 'Come', 'guys', ',', 'play', 'NLP', 'techniques', '.', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**"
      ],
      "metadata": {
        "id": "bW-49wBJMnny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmas = [token.lemma_ for token in doc]\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njuqlxDxMmvr",
        "outputId": "ad420249-8262-4764-ab90-2f89a0dc35d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hy', 'my', 'name', 'be', 'nikhil', 'and', 'it', 'be', 'a', 'nice', 'experience', 'with', 'NLP', '.', 'come', 'on', 'guy', ',', 'do', 'play', 'with', 'NLP', 'technique', '.', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parts of Speech (POS)**"
      ],
      "metadata": {
        "id": "AVzFiMTdM3Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nqp90WpfMyxi",
        "outputId": "c6281235-ccdc-4be9-f210-5b5be9f9870a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hy', 'INTJ'), ('my', 'PRON'), ('name', 'NOUN'), ('is', 'AUX'), ('nikhil', 'ADJ'), ('and', 'CCONJ'), ('it', 'PRON'), ('was', 'AUX'), ('a', 'DET'), ('nice', 'ADJ'), ('experience', 'NOUN'), ('with', 'ADP'), ('NLP', 'PROPN'), ('.', 'PUNCT'), ('Come', 'VERB'), ('on', 'ADP'), ('guys', 'NOUN'), (',', 'PUNCT'), ('Do', 'AUX'), ('play', 'VERB'), ('with', 'ADP'), ('NLP', 'PROPN'), ('techniques', 'NOUN'), ('.', 'PUNCT'), (\"'\", 'PUNCT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition**"
      ],
      "metadata": {
        "id": "b6z-PRRwM-Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
        "print(entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ7e3FXaM-3C",
        "outputId": "b914abb3-c6a4-4091-a92a-a25c4d2cdfb2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('NLP', 'ORG'), ('NLP', 'ORG')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Non-Alphabetic Tokens**"
      ],
      "metadata": {
        "id": "zNepD13rNOsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_alpha = [token.text for token in doc if token.is_alpha]\n",
        "print(\"Alphabetic Tokens:\", tokens_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkGzTCsLNMD7",
        "outputId": "ace295a1-f780-4027-c009-51186298c5a0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alphabetic Tokens: ['Hy', 'my', 'name', 'is', 'nikhil', 'and', 'it', 'was', 'a', 'nice', 'experience', 'with', 'NLP', 'Come', 'on', 'guys', 'Do', 'play', 'with', 'NLP', 'techniques']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dependency parsing**"
      ],
      "metadata": {
        "id": "zL5jGeb4I_jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dependencies = [(token.text, token.dep_, token.head.text) for token in doc]\n",
        "print(dependencies)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqElJ8ILNZqj",
        "outputId": "2cf4df57-0f39-4382-bc95-2650542a818c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hy', 'intj', 'is'), ('my', 'poss', 'name'), ('name', 'nsubj', 'is'), ('is', 'ROOT', 'is'), ('nikhil', 'acomp', 'is'), ('and', 'cc', 'is'), ('it', 'nsubj', 'was'), ('was', 'conj', 'is'), ('a', 'det', 'experience'), ('nice', 'amod', 'experience'), ('experience', 'attr', 'was'), ('with', 'prep', 'experience'), ('NLP', 'pobj', 'with'), ('.', 'punct', 'was'), ('Come', 'advcl', 'play'), ('on', 'prep', 'Come'), ('guys', 'pobj', 'on'), (',', 'punct', 'Come'), ('Do', 'aux', 'play'), ('play', 'ROOT', 'play'), ('with', 'prep', 'play'), ('NLP', 'compound', 'techniques'), ('techniques', 'pobj', 'with'), ('.', 'punct', 'play'), (\"'\", 'punct', 'play')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Noun-Chunk Extraction**"
      ],
      "metadata": {
        "id": "KVxeI0QWNmJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
        "print(\"Noun Chunks:\", noun_chunks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfrwJVB1KbVK",
        "outputId": "facc0d71-74a8-4250-b744-f32b3d24d87b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noun Chunks: ['my name', 'it', 'a nice experience', 'NLP', 'guys', 'NLP techniques']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalizing Text (Lowercasing, Removing Punctuation and Stop Words)**"
      ],
      "metadata": {
        "id": "kJ0IrgguNwwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_tokens = [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "print(normalized_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0uKTPx_N6Lt",
        "outputId": "34a0f63c-db3e-45c4-c44a-ab6be405bcb4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hy', 'nikhil', 'nice', 'experience', 'nlp', 'come', 'guy', 'play', 'nlp', 'technique']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Pipeline Component (Adding a Simple Custom Component)**"
      ],
      "metadata": {
        "id": "hZkx71xoOJ9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.tokens import Token\n",
        "\n",
        "# Registering a new custom attribute\n",
        "Token.set_extension(\"is_upper\", getter=lambda token: token.text.isupper())\n",
        "\n",
        "# Using the custom attribute\n",
        "custom_attributes = [(token.text, token._.is_upper) for token in doc]\n",
        "print(custom_attributes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcTWZl-IOBwa",
        "outputId": "fdf5b983-37ec-484b-8f11-e5d7f81945a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hy', False), ('my', False), ('name', False), ('is', False), ('nikhil', False), ('and', False), ('it', False), ('was', False), ('a', False), ('nice', False), ('experience', False), ('with', False), ('NLP', True), ('.', False), ('Come', False), ('on', False), ('guys', False), (',', False), ('Do', False), ('play', False), ('with', False), ('NLP', True), ('techniques', False), ('.', False), (\"'\", False)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence Boundary Detection**"
      ],
      "metadata": {
        "id": "_YgNEoQkOLPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [sent.text for sent in doc.sents]\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGWw56yIOLhK",
        "outputId": "566cd4ab-1684-4430-97c1-cb7ea4af9c13"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hy my name is nikhil and it was a nice experience with NLP.', \"Come on guys, Do play with NLP techniques.'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extracting Subtrees**"
      ],
      "metadata": {
        "id": "4TJ72cH9OVv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subtrees = [list(token.subtree) for token in doc]\n",
        "subtree_texts = [\" \".join([t.text for t in subtree]) for subtree in subtrees]\n",
        "print(subtree_texts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wQkbMeAOVTC",
        "outputId": "2743a0a3-da74-423f-930e-1b7d5a658c4d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hy', 'my', 'my name', 'Hy my name is nikhil and it was a nice experience with NLP .', 'nikhil', 'and', 'it', 'it was a nice experience with NLP .', 'a', 'nice', 'a nice experience with NLP', 'with NLP', 'NLP', '.', 'Come on guys ,', 'on guys', 'guys', ',', 'Do', \"Come on guys , Do play with NLP techniques . '\", 'with NLP techniques', 'NLP', 'NLP techniques', '.', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Word Shape Features**"
      ],
      "metadata": {
        "id": "wSLvSbynOsyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_shapes = [(token.text, token.shape_) for token in doc]\n",
        "print( word_shapes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTvZeubZOvvK",
        "outputId": "9ab2e928-55f1-44b8-bea6-41f28200ee52"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hy', 'Xx'), ('my', 'xx'), ('name', 'xxxx'), ('is', 'xx'), ('nikhil', 'xxxx'), ('and', 'xxx'), ('it', 'xx'), ('was', 'xxx'), ('a', 'x'), ('nice', 'xxxx'), ('experience', 'xxxx'), ('with', 'xxxx'), ('NLP', 'XXX'), ('.', '.'), ('Come', 'Xxxx'), ('on', 'xx'), ('guys', 'xxxx'), (',', ','), ('Do', 'Xx'), ('play', 'xxxx'), ('with', 'xxxx'), ('NLP', 'XXX'), ('techniques', 'xxxx'), ('.', '.'), (\"'\", \"'\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Token Similarity**"
      ],
      "metadata": {
        "id": "Qkm6YdgHOxuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_similarity = [(token1.text, token2.text, token1.similarity(token2)) for token1 in doc for token2 in doc if token1 != token2]\n",
        "print(token_similarity[:5])  # Displaying the first 5 for brevity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2UtnEyfOx7S",
        "outputId": "0cf486a3-9f10-4f32-af86-69bee089802b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hy', 'my', 0.2780427932739258), ('Hy', 'name', 0.09494823962450027), ('Hy', 'is', -0.024768082424998283), ('Hy', 'nikhil', 0.11030188202857971), ('Hy', 'and', 0.3212807774543762)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-8a05bb0fe10d>:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  token_similarity = [(token1.text, token2.text, token1.similarity(token2)) for token1 in doc for token2 in doc if token1 != token2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Counter**"
      ],
      "metadata": {
        "id": "EDWpVMjrJHFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install Counter"
      ],
      "metadata": {
        "id": "AKfFv7w9WjgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c75026-00e8-4535-fa9b-67416b9f665b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Counter\n",
            "  Downloading Counter-1.0.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Counter\n",
            "  Building wheel for Counter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Counter: filename=Counter-1.0.0-py3-none-any.whl size=5394 sha256=b6351e594a7448bffb3dbc2ad9153d3a870666bbea33e89e7a3039e64ba0d536\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/02/6d/d5c0838427a060718c6060ae4d24da95a0e0df0d7a3dab8040\n",
            "Successfully built Counter\n",
            "Installing collected packages: Counter\n",
            "Successfully installed Counter-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "count=Counter(s)\n",
        "count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV2wTaGRIv8b",
        "outputId": "ec406457-1368-413a-8315-a89e02444933"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'h': 2,\n",
              "         'y': 1,\n",
              "         ' ': 3,\n",
              "         'n': 3,\n",
              "         'i': 4,\n",
              "         'k': 1,\n",
              "         'l': 1,\n",
              "         'c': 2,\n",
              "         'e': 5,\n",
              "         'x': 1,\n",
              "         'p': 1,\n",
              "         'r': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xmrKroBKaLL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}